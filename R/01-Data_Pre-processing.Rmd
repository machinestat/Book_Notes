---
title: "Data Pre-processing"
output: pdf_document
---

Data pre-processing techniques generally refer to the addition, deletion, or transformation of training set data, and data preparation can make or break a model's predictive ability.

## 1.1 Cell Segmentation in High-content Screening
```{r}
library(AppliedPredictiveModeling)
data(segmentationOriginal)
## Retain the original training set
segTrain <- subset(segmentationOriginal, Case == "Train")

## Remove the first three columns (identifier columns)
segTrainX <- segTrain[, -(1:3)]
segTrainClass <- segTrain$Class
```

## 1.2 Data Transformations for Individual Predictors
**_Centering and Scaling_**
To center a predictor variable, the average predictor value is subtracted from all values, and the predictor has a zero mean after this. To scale the data, each value of the predictor variable is divided by its standard deviation, and this will coerce the values to have a common standard deviation of one. Some models, such as PLS, benefit from the predictors being on a common scale. The only real downside to these transformations is a loss of interpretability of the individual values since the data are no longer in the original units.

**_Transformations to Resolve Skewness_**
An un-skewed distribution is one that is roughly symmetric. This means that the probability of falling on either side of the distribution's mean is roughly equal. A right skewed distribution has a larger number of points on the left side of the distribution (smaller values) than on the right side (larger values). A general rule of thumb to consider is that skewed data whose ratio of the highest value to the lowest value is greater than 20 have significant skewness. The skewness statistic value will be close to zero if the distribution of the predictor variable is roughly symmetric. The skewness statistic becomes larger as the distribution becomes more right skewed. Similarly, as the distribution becomes more left skewed, the value becomes negative. The formula for the sample skewness statistic is

$skewness = \frac{\sum \left ( x_{i}-\bar{x} \right )}{\left ( n-1 \right )v^{\frac{3}{2}}}$    
where $v = \frac{\sum \left ( x_{i}- \bar{x}\right )}{\left ( n-1 \right )}$

Replacing the data with the log, square root, or inverse may help to remove the skew.

**Example** The column VarIntenCh3 measures the standard deviation of the intensity of the pixels in the actin filaments
```{r}
max(segTrainX$VarIntenCh3)/min(segTrainX$VarIntenCh3)

library(e1071)
skewness(segTrainX$VarIntenCh3)
par(mfrow = c(1,2))
par(mar = c(2, 2, 4, 2) + 0.1)
hist(segTrainX$VarIntenCh3, ylab = "Count", xlab = "Natural Units",
     xlim = c(0, 800), ylim = c(0, 400), main = "")
box()
## Histogram after log transformation
hist(log(segTrainX$VarIntenCh3), ylab  ="", xlab = "Log Units",
     xlim = c(0, 8), ylim = c(0, 250), main = "")
box()
```
Alternatively, statistical methods can be used to empirically identify an
appropriate transformation. Box and Cox (1964) propose a family of transformations3 that are indexed by a parameter, denoted as:  
$x^{*}=\left\{\begin{matrix}
\frac{x^{\lambda }-1}{\lambda }  \\ log(x)  
\end{matrix}\right.$

```{r}
## Use caret's preProcess function to transform for skewness
library(caret)
segPP <- preProcess(segTrainX, method = "BoxCox")

## Apply the transformations
segTrainTrans <- predict(segPP, segTrainX)

## Results for a single predictor
segPP$bc$VarIntenCh3

## Another predictor,the estimated cell perimeter,had an estimate of âˆ’1.1.
segPP$bc$PerimCh1

histogram(~segTrainX$PerimCh1,
          xlab = "Natural Units",
          type = "count")

histogram(~segTrainTrans$PerimCh1,
          xlab = "Transformed Data",
          ylab = " ",
          type = "count")
```

## 1.3 **Data Transformation for Multiple Predictors**
These transformations act on groups of predictors, typicall the entire data set. Of primary importance are methods to resolve outliers and reduce the dimention of the data.

### **_Transformations to Resolve Outliers_**

Generally define outliers as samples exceptionally far from the mainstream of the data set. We can often identify an unusuall by looking at a figure.
When one or more samples are suspected to be ourliers, the first step is to make sure that the values are scientifically valid, and that no data recording errors have occurred. Great care should be taken not to hastily remove or change any values, especially the sample size is small. With small samle sizes, apparent outliers might be a skewed distribution where there are not yet enogh data to show the skewness. 

If a model is considered to be sensitive to outliers, one data transformation that can minimize the problem is the _spatial sign_. This procedure projects the the predictor values onto a multidimensional sphere. This has an effect of making all the samples the same distance from the center of the sphere. Mathematically, each sample divided by its squared norm:

$$ x^{*}_{ij}=\frac{x_{ij}}{\sum_{j=1}^{p}x_{ij}^{2}}$$

Since the denominator is intended to measure the squared distance to the center of the predictor's distribution, it is important to center and scale the predictor data prior to using this transformation. This manipulation of predictors transform them as a group, after removing predictor variables after applying spatial sign transformation may be problematic.

### Computing
```{r}
library(AppliedPredictiveModeling)
data(segmentationOriginal)
segData <- subset(segmentationOriginal, Case == "Train")

# The class and Cell fields will be saved into separate vectors, then removed from the main object.

cellID <- segData$Cell
Class <- segData$Class
case <- segData$Case
# Now remove the columns
segData <- segData[, -c(1:3)]
# Remove the original data contained several "status" columns which were binary versin of the predictors.
statusColNum <- grep("Status", names(segData))
statusColNum
segData <- segData[, -statusColNum]
```

**Transformation**

Some features exhibited significantly skewness. The *skewness* function in the *e1071* package calculates the sample skewness statistic for each predictor:
```{r}
library(e1071)
# For one predictor
skewness(segData$AngleCh1)
# Since all the predictors are numeric columns, the apply function can be used to compute the skewness across columns.
skewValue <- apply(segData, 2, skewness)
head(skewValue)

# A caret function, BoxCoxTrans, can find the appropriate transformation and apply them to the new data.
library(caret)
Ch1AreaTrans <- BoxCoxTrans(segData$AreaCh1)
Ch1AreaTrans

# The original data
head(segData$AreaCh1)
# After transformation
head(predict(Ch1AreaTrans, segData$AreaCh1))
(819^(-0.9) - 1)/(-0.9)

```

The R base function prcomp can be used for PCA, the data are centered and scaled prior to PCA.
```{r}
pcaObject <- prcomp(segData, center = TRUE, scale. = TRUE)
# Calculate the cumulative percentage of variance which each component account for
percentVariance <- pcaObject$sd^2/sum(pcaObject$sd^2)*100

```
